---
title: Api Embedding
emoji: ğŸ 
colorFrom: green
colorTo: purple
sdk: docker
pinned: false
---

# ğŸ§  Unified Embedding API

> ğŸ§© Unified API for all your Embedding, Sparse & Reranking Models â€” plug and play with any model from Hugging Face or your own fine-tuned versions.

---

## ğŸš€ Overview

**Unified Embedding API** is a modular and open-source **RAG-ready API** built for developers who want a simple, unified way to access **dense**, **sparse**, and **reranking** models.

It's designed for **vector search**, **semantic retrieval**, and **AI-powered pipelines** â€” all controlled from a single `config.yaml` file.

âš ï¸ **Note:** This is a development API.  
For production deployment, host it on cloud platforms such as **Hugging Face TEI**, **AWS**, **GCP**, or any cloud provider of your choice.

---

## ğŸ§© Features

- ğŸ§  **Unified Interface** â€” One API to handle dense, sparse, and reranking models
- âš¡ **Batch Processing** â€” Automatic single/batch detection
- ğŸ”§ **Flexible Parameters** â€” Full control via kwargs and options
- ğŸ”Œ **OpenAI Compatible** â€” Works with OpenAI client libraries
- ğŸ“ˆ **RAG Support** â€” Perfect base for Retrieval-Augmented Generation systems
- âš¡ **Fast & Lightweight** â€” Powered by FastAPI and optimized with async processing
- ğŸ§° **Extendable** â€” Switch models instantly via `config.yaml` and add your own models effortlessly

---

## ğŸ“ Project Structure

```
unified-embedding-api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ embeddings.py  # endpoint sparse & dense   
â”‚   â”‚       â”œâ”€â”€ models.py
â”‚   â”‚       â”œâ”€â”€ health.py
â”‚   â”‚       â””â”€â”€ rerank.py      # endpoint reranking
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”‚   â””â”€â”€ manager.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”‚   â”œâ”€â”€ dense.py       # dense model
â”‚   â”‚   â”‚   â”œâ”€â”€ sparse.py      # sparse model
â”‚   â”‚   â”‚   â””â”€â”€ rank.py        # reranking model
â”‚   â”‚   â””â”€â”€ schemas/
â”‚   â”‚       â”œâ”€â”€ common.py
â”‚   â”‚       â”œâ”€â”€ requests.py       
â”‚   â”‚       â””â”€â”€ responses.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â””â”€â”€ models.yaml        # add/change models here
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ validators.py
â”‚
â”œâ”€â”€ app.py                         
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ğŸ§© Model Selection

Default configuration is optimized for **CPU 2vCPU / 16GB RAM**. See [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) for model recommendations and memory usage reference.

**Add More Models:** Edit `src/config/models.yaml`

```yaml
models:
  your-model-name:
    name: "org/model-name"
    type: "embeddings"  # or "sparse-embeddings" or "rerank"
```

âš ï¸ If you plan to use larger models like `Qwen2-embedding-8B`, please upgrade your Space.

---

## â˜ï¸ How to Deploy (Free ğŸš€)

Deploy your **Custom Embedding API** on **Hugging Face Spaces** â€” free, fast, and serverless.

### **1ï¸âƒ£ Deploy on Hugging Face Spaces (Free!)**

1. **Duplicate this Space:**  
   ğŸ‘‰ [fahmiaziz/api-embedding](https://huggingface.co/spaces/fahmiaziz/api-embedding)  
   Click **â‹¯** (three dots) â†’ **Duplicate this Space**

2. **Add HF_TOKEN environment variable**. Make sure your space is public

3. **Clone your Space locally:**  
   Click **â‹¯** â†’ **Clone repository**
   ```bash
   git clone https://huggingface.co/spaces/YOUR_USERNAME/api-embedding
   cd api-embedding
   ```

4. **Edit `src/config/models.yaml`** to customize models:
   ```yaml
   models:
     your-model:
       name: "org/model-name"
       type: "embeddings"  # or "sparse-embeddings" or "rerank"
   ```

5. **Commit and push changes:**
   ```bash
   git add src/config/models.yaml
   git commit -m "Update models configuration"
   git push
   ```

6. **Access your API:**  
   Click **â‹¯** â†’ **Embed this Space** â†’ copy **Direct URL**
   ```
   https://YOUR_USERNAME-api-embedding.hf.space
   https://YOUR_USERNAME-api-embedding.hf.space/docs  # Interactive docs
   ```

That's it! You now have a live embedding API endpoint powered by your models.

### **2ï¸âƒ£ Run Locally (NOT RECOMMENDED)**

```bash
# Clone repository
git clone https://github.com/fahmiaziz98/unified-embedding-api.git
cd unified-embedding-api

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run server
python app.py
```

API available at: `http://localhost:7860`

### **3ï¸âƒ£ Run with Docker**

```bash
# Build and run
docker-compose up --build

# Or with Docker only
docker build -t embedding-api .
docker run -p 7860:7860 embedding-api
```

---

## ğŸ“– Usage Examples

### **Python with Native API**

```python
import requests

base_url = "https://fahmiaziz-api-embedding.hf.space/api/v1"

# Single embedding
response = requests.post(f"{base_url}/embeddings", json={
    "input": "What is artificial intelligence?",
    "model": "qwen3-0.6b"
})
embeddings = response.json()["data"]

# Batch embeddings with options
response = requests.post(f"{base_url}/embeddings", json={
    "input": ["First document", "Second document", "Third document"],
    "model": "qwen3-0.6b",
    "options": {
        "normalize_embeddings": True
    }
})
batch_embeddings = response.json()["data"]
```

### **cURL**

```bash
# Dense embeddings
curl -X POST "https://fahmiaziz-api-embedding.hf.space/api/v1/embeddings" \
  -H "Content-Type: application/json" \
  -d '{
    "input": ["Hello world"],
    "model": "qwen3-0.6b"
  }'

# Sparse embeddings
curl -X POST "https://fahmiaziz-api-embedding.hf.space/api/v1/embed_sparse" \
  -H "Content-Type: application/json" \
  -d '{
    "input": ["First doc", "Second doc", "Third doc"],
    "model": "splade-pp-v2"
  }'

# Reranking
curl -X POST "https://fahmiaziz-api-embedding.hf.space/api/v1/rerank" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Python for data science",
    "documents": [
      "Python is great for data science",
      "Java is used for enterprise apps",
      "R is for statistical analysis"
    ],
    "model": "bge-v2-m3",
    "top_k": 2
  }'
```

### **JavaScript/TypeScript**

```typescript
const baseUrl = "https://fahmiaziz-api-embedding.hf.space/api/v1";

// Using fetch
const response = await fetch(`${baseUrl}/embeddings`, {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    texts: ["Hello world"],
    model_id: "qwen3-0.6b",
  }),
});

const { embeddings } = await response.json();
console.log(embeddings);
```

---

## ğŸ“Š API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/embeddings` | POST | Generate embeddings (OpenAI compatible) |
| `/api/v1/embed_sparse` | POST | Generate sparse embeddings |
| `/api/v1/rerank` | POST | Rerank documents by relevance |
| `/api/v1/models` | GET | List available models |
| `/api/v1/models/{model_id}` | GET | Get model information |
| `/health` | GET | Health check |
| `/` | GET | API information |
| `/docs` | GET | Interactive API documentation |

---

## ğŸ”Œ OpenAI Client Compatibility

This API is **fully compatible** with OpenAI's client libraries, making it a drop-in replacement for OpenAI's embedding API.

### **Why use OpenAI client?**

âœ… **Familiar API** â€” Same interface as OpenAI  
âœ… **Type Safety** â€” Full type hints and IDE support  
âœ… **Error Handling** â€” Built-in retry logic and error handling  
âœ… **Async Support** â€” Native async/await support  
âœ… **Easy Migration** â€” Switch between OpenAI and self-hosted seamlessly

### **Supported Features**

| Feature | Supported | Notes |
|---------|-----------|-------|
| `embeddings.create()` | âœ… Yes | Single and batch inputs |
| `input` as string | âœ… Yes | Auto-converted to list |
| `input` as list | âœ… Yes | Batch processing |
| `model` parameter | âœ… Yes | Use your model IDs |
| `encoding_format` | âš ï¸ Partial | Always returns `float` |

### **Example with OpenAI Client (Compatible!)**

```python
from openai import OpenAI

# Initialize client with your API endpoint
client = OpenAI(
    base_url="https://fahmiaziz-api-embedding.hf.space/api/v1",
    api_key="-"  # API key not required, but must be present
)

# Generate embeddings
embedding = client.embeddings.create(
    input="Hello",
    model="qwen3-0.6b"
)

# Access results
for item in embedding.data:
    print(f"Embedding: {item.embedding[:5]}...")  # First 5 dimensions
    print(f"Index: {item.index}")
```

### **Async OpenAI Client**

```python
from openai import AsyncOpenAI

# Initialize async client
client = AsyncOpenAI(
    base_url="https://fahmiaziz-api-embedding.hf.space/api/v1",
    api_key="-"
)

# Generate embeddings asynchronously
async def get_embeddings():
    try:
        embedding = await client.embeddings.create(
            input=["Hello", "World", "AI"],
            model="qwen3-0.6b"
        )
        return embedding
    except Exception as e:
        print(f"Error: {e}")

# Use in async context
embeddings = await get_embeddings()
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“š Resources

- [API Documentation](API.md)
- [Sentence Transformers](https://www.sbert.net/)
- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [OpenAI Python Client](https://github.com/openai/openai-python)
- [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)
- [Hugging Face Spaces](https://huggingface.co/docs/hub/spaces)
- [Deploy Applications on Hugging Face Spaces](https://huggingface.co/blog/HemanthSai7/deploy-applications-on-huggingface-spaces)
- [Sync HF Spaces with GitHub](https://github.com/ruslanmv/How-to-Sync-Hugging-Face-Spaces-with-a-GitHub-Repository)
- [Duplicate & Clone Spaces](https://huggingface.co/docs/hub/spaces-overview#duplicating-a-space)

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Sentence Transformers** for the embedding models
- **FastAPI** for the excellent web framework
- **Hugging Face** for model hosting and Spaces
- **OpenAI** for the client library design
- **Open Source Community** for inspiration and support

---

## ğŸ“ Support

- **Issues:** [GitHub Issues](https://github.com/fahmiaziz98/unified-embedding-api/issues)
- **Discussions:** [GitHub Discussions](https://github.com/fahmiaziz98/unified-embedding-api/discussions)
- **Hugging Face Space:** [fahmiaziz/api-embedding](https://huggingface.co/spaces/fahmiaziz/api-embedding)

---

<div align="center">

Made with â¤ï¸ by the Open-Source Community

> âœ¨ "Unify your embeddings. Simplify your AI stack."

</div>